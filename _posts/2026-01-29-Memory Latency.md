---
layout: post
title: "Memory Latency"
date: 2026-01-27 00:00:00 +0900
author: kang
categories: [Computer Structure, Memory]
tags: [Computer Structure, Components, CPU, Latency, SSD, Cache, RAM]
pin: false
math: true
mermaid: true

---
# üß† Memory Latency Hierarchy ‚Äî Why Caches Matter

![Latency](/assets/img/develop/2026-01-29-Memory-Latency.png)

This table compares **hardware access latency** with a **scaled real-world time analogy**  
to illustrate how dramatically access time increases across memory/storage layers.

---

## 1Ô∏è‚É£ Memory Access Latency Comparison

| System Event | Actual Latency | Scaled Human-Time Analogy |
|-------------|---------------|----------------------------|
| **CPU Register / 1 CPU cycle** | ~0.4 ns | **1 second** |
| **L1 Cache Access** | ~0.9 ns | **2 seconds** |
| **L2 Cache Access** | ~2.8 ns | **7 seconds** |
| **L3 Cache Access** | ~28 ns | **1 minute** |
| **Main Memory (RAM)** | ~100 ns | **4 minutes** |
| **Optane / Persistent Memory** | ~10 ¬µs | **7 hours** |
| **NVMe SSD I/O** | ~25 ¬µs | **17 hours** |
| **SSD I/O** | ~50‚Äì150 ¬µs | **1.5‚Äì4 days** |
| **HDD (Rotational Disk)** | ~1‚Äì10 ms | **1‚Äì9 months** |
| **Internet (SF ‚Üí NYC)** | ~65 ms | **5 years** |
| **Internet (SF ‚Üí Hong Kong)** | ~141 ms | **11 years** |

---

## 2Ô∏è‚É£ Key Insight ‚Äî Latency Grows Explosively

Each step down the hierarchy is **orders of magnitude slower**:

- Register ‚Üí Cache: **~2√ó slower**
- Cache ‚Üí RAM: **~100√ó slower**
- RAM ‚Üí SSD: **~1,000√ó slower**
- SSD ‚Üí HDD: **~10,000√ó slower**
- Disk ‚Üí Internet: **Millions of times slower**

> This is why **memory locality and caching dominate real-world performance**.

---

## 3Ô∏è‚É£ Why Data Is Accessed in This Order  
### (L1 ‚Üí L2 ‚Üí L3 ‚Üí RAM ‚Üí Storage)

### ‚úÖ Reason 1 ‚Äî **Speed vs Cost Tradeoff**

| Layer | Speed | Cost | Capacity |
|------|------|------|---------|
| Registers | Fastest | Very expensive | Tiny |
| L1 Cache | Very fast | Expensive | Small |
| L2 Cache | Fast | Expensive | Medium |
| L3 Cache | Slower | Cheaper | Larger |
| RAM | Much slower | Affordable | Large |
| Storage | Slowest | Cheapest | Huge |

**We cannot build large memory entirely from ultra-fast storage ‚Äî too expensive and power-hungry.**

---

### ‚úÖ Reason 2 ‚Äî **Locality of Reference**

![Locality](/assets/img/develop/2026-01-29-Locality.png)

Programs tend to:
- Reuse **recent data** (temporal locality)
- Access **nearby memory** (spatial locality)

So CPU checks **fast memory first**, because it is **likely already there**.

---

### ‚úÖ Reason 3 ‚Äî **Avoiding Massive Stall Time**

If CPU accessed RAM every time:

- Pipeline stalls
- CPU idle time skyrockets
- Performance collapses

Caches **hide RAM latency** so the CPU stays busy.

---

### ‚úÖ Reason 4 ‚Äî **Hierarchical Filtering Model**

Think of memory like a search chain:

