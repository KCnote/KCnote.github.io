---
layout: post
title: "Unsupervised Learning"
date: 2026-02-10 00:00:00 +0900
author: kang
categories: [Machince Learning, Unsupervised]
tags: [Machince Learning, Unsuperviseding, Overview]
pin: false
math: true
mermaid: true
---

# ğŸ§  Unsupervised Learning & Clustering

> Lecture-style structured notes with intuition, examples, and math

---

## ğŸ“Œ Why Unsupervised Learning?

### ğŸ¯ Goal
Unsupervised learning aims to **discover interesting structure** in data **without labels**.

- ğŸ” Discover **subgroups / patterns** among observations or variables
- ğŸ“Š Find informative ways to **visualize high-dimensional data**

### ğŸ’¡ Why is it important?
- Unlabeled data is **easier and cheaper** to obtain
- Labeling requires **human labor & expertise**

### âš ï¸ Key Characteristic
- No single objective like prediction accuracy
- Results are often **subjective**

---

## ğŸ§© Clustering Problem

### ğŸ“– Definition
Finding **natural groupings** among objects.

### âœ… Objective
- High **intra-cluster similarity**
- Low **inter-cluster similarity**

---

## ğŸ§ª Clustering Examples

### ğŸ§¬ Gene Clustering
- Microarrays measure gene activity across conditions
- Similar expression patterns â†’ clustered genes
- Helps infer **functions of unknown genes**

---

### ğŸ‘¤ User Clustering (Recommendation Systems)
- Core idea of **collaborative filtering**
- Users with similar tastes are grouped

> â€œUsers like you also liked â€¦â€

---

### ğŸ–¼ï¸ Image Compression

Each pixel is a vector:
$$
\mathbf{x}_i = [R_i, G_i, B_i]^T
$$

Cluster centers:
$$
\{\mu_1, \mu_2, \dots, \mu_K\}
$$

Assignment:
$$
\arg\min_k \| \mathbf{x}_i - \mu_k \|_2
$$

Fewer colors â†’ smaller storage size

---

## ğŸ†š Classification vs Clustering

| Classification | Clustering |
|---------------|------------|
| Uses labels | No labels |
| Predict class | Discover structure |
| Supervised | Unsupervised |

---

## ğŸ­ Clustering is Subjective

There is **no single correct clustering**.

Possible groupings:
- Family-based
- Gender-based
- Occupation-based

Depends on **similarity definition**.

---

## ğŸ“ Similarity / Distance Metrics

### L1 Distance
$$
L_1(A,B) = \sum_{i,j} |A_{ij} - B_{ij}|
$$

### L2 Distance
$$
L_2(A,B) = \sqrt{ \sum_{i,j} (A_{ij} - B_{ij})^2 }
$$

### Distance Matrix
$$
D =
\begin{bmatrix}
0 & d_{12} & d_{13} \\
d_{21} & 0 & d_{23} \\
d_{31} & d_{32} & 0
\end{bmatrix}
$$

---

## ğŸ§± Two Types of Clustering

### ğŸŒ² Hierarchical Clustering
- Bottom-up (agglomerative)
- Produces a dendrogram

### ğŸ“¦ Partitional Clustering
- Top-down
- Requires number of clusters K
- Example: K-means

---

## ğŸ§  Summary

- Unsupervised learning finds structure without labels
- Clustering is the most common technique
- Results depend on:
  - Distance metric
  - Number of clusters
  - Interpretation goal
