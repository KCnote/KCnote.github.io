---
layout: post
title: "Optimization and Gradient Descent"
date: 2026-02-06 00:00:00 +0900
author: kang
categories: [Machince Learning, Optimization]
tags: [Machince Learning, Overview, ML, Supervised, Classification, MLE, Optimization, Gradient Descent]
pin: false
math: true
mermaid: true
---

# ğŸš€ Optimization in Machine Learning â€” Styled Notes

> ğŸ“˜ Clean, blogâ€‘ready version with emojis & visual structure  
> ğŸ¯ All original content preserved (no omission)  

---

# ğŸ§  What is Optimization?

According to Wikipedia:

> **Mathematical optimization** is the process of selecting the **best element**,
> according to some **criterion**, from a set of possible alternatives.

---

## ğŸ”‘ Key Components of Optimization

Every optimization problem has three essential parts:

### 1ï¸âƒ£ Candidates (Alternatives)
Possible solutions to the problem.

Examples:
- Model parameters
- Actions
- Decisions

---

### 2ï¸âƒ£ Criterion (Objective Function)

A function measuring how good a candidate is.

$$
\mathcal{L}(\hat{y}, y)
$$

or

$$
J(\theta)
$$

Examples:
- Loss function ğŸ“‰  
- Cost function ğŸ“Š  
- Likelihood function ğŸ“ˆ  

---

### 3ï¸âƒ£ Best Element

Goal: find the optimal candidate.

$$
\theta^* = \arg\min_{\theta} J(\theta)
$$

or

$$
\theta^* = \arg\max_{\theta} J(\theta)
$$

---

## ğŸ¤– Optimization in Machine Learning

In ML:

- Candidates â†’ model parameters âš™ï¸  
- Criterion â†’ loss function ğŸ“‰  
- Optimization â†’ learning parameters from data ğŸ§   

Examples:

- Linear Regression â†’ minimize squared error  
- Logistic Regression â†’ maximize likelihood / minimize crossâ€‘entropy  

---

# ğŸ” Primitive Ideas in Optimization

Before advanced methods, simple strategies help build intuition.

---

## Basic Approaches

### ğŸ” 1. Exhaustive Search
Try all parameter combinations.

- Guarantees global optimum âœ”  
- Computationally expensive âŒ  

---

### ğŸ² 2. Random Search
Randomly sample candidate solutions.

- Often effective in high dimension  
- No guarantee of optimum  

---

### ğŸ“Š 3. Visualization
Visualize objective function when possible.

Helps understand:
- Loss surface shape  
- Local minima / maxima  
- Convexity vs nonâ€‘convexity  

---

### ğŸ§© 4. Greedy Search
Optimize one variable at a time.

- Simple âœ”  
- May get stuck in local optimum âŒ  

---

## ğŸ’¡ Key Insight

These ideas motivate modern optimization methods:

- Gradient Descent ğŸ“‰  
- Stochastic Gradient Descent (SGD) âš¡  
- Newtonâ€™s Method ğŸ“  
- Convex Optimization  

---

# â›°ï¸ Following the Slope â€” Gradient Descent

## Objective

Minimize loss function:

$$
\min_{\boldsymbol{\beta}} \mathcal{L}(\boldsymbol{\beta})
$$

---

## Core Idea

At current parameters:

1. Compute gradient

$$
\nabla_{\boldsymbol{\beta}} \mathcal{L}(\boldsymbol{\beta})
$$

2. Move in **negative gradient direction**
3. Repeat until convergence

---

## ğŸ“ Update Rule

$$
\boldsymbol{\beta}^{(t+1)}
=
\boldsymbol{\beta}^{(t)}
-
\eta \, \nabla_{\boldsymbol{\beta}} \mathcal{L}(\boldsymbol{\beta}^{(t)})
$$

Where:

- $\eta$ = learning rate  
- Gradient = steepest ascent direction  
- Negative gradient = steepest descent  

---

## ğŸ¤” Why Negative Gradient?

- Gradient â†’ steepest increase â¬†ï¸  
- Negative gradient â†’ steepest decrease â¬‡ï¸  
- Leads toward minimum ğŸ¯  

---

## ğŸ“˜ Interpretation

- Gradient = best local linear approximation  
- Each step slightly improves parameters  
- Repeated updates â†’ reach minimum  

---

## ğŸŒ Where Gradient Descent is Used

- Linear Regression  
- Logistic Regression  
- Neural Networks  
- Deep Learning  

---

# ğŸ“ Gradient Descent (Vector Form)

$$
\boldsymbol{\beta}^{new} = \boldsymbol{\beta}^{old} - \alpha \nabla_{\boldsymbol{\beta}} \mathcal{L}(\boldsymbol{\beta})
$$

Where $\alpha$ = learning rate.

---

## Single Parameter Form

$$
\beta_i^{new} = \beta_i^{old} - \alpha \frac{\partial}{\partial \beta_i}\mathcal{L}(\boldsymbol{\beta})
$$

- If slope < 0 â†’ parameter increases  
- If slope > 0 â†’ parameter decreases  

---

## ğŸ’» Pseudocode

```python
beta = rand(vector)

while True:
    beta_grad = evaluate_gradient(L, data, beta)
    beta = beta - alpha * beta_grad

    if norm(beta_grad) <= threshold:
        break
```

---

## ğŸ§  Intuition

- Gradient â†’ steepest ascent  
- Negative gradient â†’ reduce loss  
- Iterative updates â†’ reach minimum  

---

## âš ï¸ Notes

Learning rate $\alpha$ is critical:

- Too small â†’ slow convergence ğŸ¢  
- Too large â†’ divergence / oscillation âŒ  

Convergence often when gradient norm is very small.

---

# âš ï¸ Gradient Descent â€” Potential Problems

---

## 1ï¸âƒ£ Nonâ€‘Convex Surface

Loss may not be convex:

- Multiple local minima  
- Saddle points  
- Gradient may be zero but not global optimum  

---

## 2ï¸âƒ£ Requires Differentiable Loss

Gradient descent requires differentiable cost.

0/1 loss is not differentiable â†’ use smooth surrogate:

- Logistic loss  
- Crossâ€‘entropy  
- Squared error  

---

## 3ï¸âƒ£ Slow Convergence

- Full gradient uses all data â†’ expensive  
- Large datasets â†’ slow training  
- Convergence may take long time  

---

# ğŸš€ Practical Improvements

Modern optimizers improve performance:

- Stochastic Gradient Descent (SGD) âš¡  
- Miniâ€‘Batch Gradient Descent ğŸ“¦  
- Momentum ğŸš€  
- Adam / RMSProp âš™ï¸  
- Secondâ€‘order methods (Newton, Quasiâ€‘Newton) ğŸ“  
