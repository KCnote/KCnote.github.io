---
layout: post
title: "Overfitting"
date: 2026-02-08 00:00:00 +0900
author: kang
categories: [Machince Learning, Fitting]
tags: [Machince Learning, Mathematics, ML, Supervised, Fitting, Overfitting, Underfitting, Capacity]
pin: false
math: true
mermaid: true
---

# ðŸ“˜ Training, Overfitting, Capacity & Highâ€‘Dimensional Learning

---

# ðŸ“‰ Training vs Validation Curves

## ðŸŽ¯ Overview

Training and validation curves are **core diagnostic tools** for understanding how a machine learning model learns over time.

They help detect:

- âš ï¸ Underfitting  
- âš ï¸ Overfitting  
- ðŸž Training bugs  
- âš™ï¸ Optimization failures  

We usually monitor:

$$
\text{Loss vs Epoch}
$$

---

## ðŸ“Š Typical Learning Behavior

### ðŸ”µ Training Curve

- Training loss should **monotonically decrease (overall)**.
- Indicates model is learning from training data.
- Small noise/oscillation is normal.

### ðŸ”´ Validation Curve

Typical pattern:

1. Decreases initially  
2. Reaches minimum  
3. Starts increasing  

This signals **Overfitting**.

---

## âš ï¸ Overfitting Pattern

$$
\text{Training loss} \downarrow,\quad \text{Validation loss} \uparrow
$$

Meaning:

> The model memorizes training data instead of learning general patterns.

### ðŸ›  Fix Strategies

- Early stopping  
- Regularization ($$L_2$$, Dropout)  
- More data  
- Simpler model  

---

## ðŸš¨ When Training Loss Does NOT Decrease

If training loss:

- stays flat  
- diverges  
- oscillates randomly  

âž¡ï¸ **Assume a bug first.**

### Possible Causes

1. Learning rate too high â†’ divergence  
2. Learning rate too low â†’ no learning  
3. Gradient blocked / detached  
4. Loss not connected to parameters  
5. Wrong labels / mismatch  
6. Data normalization issue  
7. Activation saturation  
8. Optimizer not updating  

### Rule

> A correct model must reduce training loss unless data is pure noise or capacity is insufficient.

---

## ðŸŒŸ Ideal Training Scenario

Good:

- Training â†“ steadily  
- Validation â†“ then stabilizes  
- Small gap between train/val  

Bad:

- Train â†“, Val â†‘ fast â†’ Overfitting  
- Train not decreasing â†’ Bug  
- Both high â†’ Underfitting  

---

# ðŸŒ Overfitting and Highâ€‘Dimensional Data

## ðŸŽ¯ Learning Goal

We care about **generalization**, not memorization.

---

## ðŸ“‰ Why Validation Loss Gets Worse

Early stage:

- Learn signal â†’ both losses decrease  

Later:

- Learn noise â†’ training â†“, validation â†‘  

âž¡ï¸ **Overfitting**

---

## ðŸ“Œ Definition of Overfitting

Model learns:

- Signal âœ”  
- Noise âŒ  

Result:

- Training improves  
- Validation worsens  

---

## ðŸ“Š Loss Interpretation

| Phase | Training | Validation | Meaning |
|------|----------|-----------|---------|
| Early | â†“ | â†“ | Learning signal |
| Optimal | Low | Lowest | Best generalization |
| Overfit | â†“ | â†‘ | Learning noise |

---

## ðŸ“ Curse of Dimensionality

If feature dimension = $$d$$:

- Space grows exponentially  
- Data becomes sparse  
- Required samples grow exponentially  

Conceptually:

$$
N \propto O(e^d)
$$

Example:

| Dimension | Needed Data |
|----------|-------------|
| 1D | ~100 |
| 10D | ~10^{10} |
| 100D | Practically impossible |

---

## ðŸ”Ž Why Highâ€‘Dim Causes Overfitting

When $$d$$ is large and data small:

- Infinite models fit training data  
- Noise easily fitted  
- Generalization collapses  

---

## ðŸ›  Practical Implications

Highâ€‘dim models require:

- More data  
- Strong regularization  
- Feature selection  
- Dimensionality reduction (PCA)  

---

# ðŸ§  Model Capacity, Overfitting & Underfitting

## ðŸ“Œ Capacity Definition

Model capacity = ability to represent complex patterns.

| Model | Capacity |
|------|----------|
| Linear | Low |
| Polynomial | Medium |
| Deep Net | High |

---

## ðŸ”´ Overfitting (High Capacity)

- Model memorizes noise  
- Very low training loss  
- Poor generalization  

---

## ðŸ”µ Underfitting (Low Capacity)

- Cannot learn signal  
- Both losses high  

---

## ðŸ“Š Biasâ€“Variance Tradeoff

$$
\text{MSE} = \text{Bias}^2 + \text{Variance} + \sigma^2
$$

| Capacity | Bias | Variance |
|----------|------|----------|
| Low | High | Low |
| Optimal | Balanced | Balanced |
| High | Low | High |

---

## ðŸ“ Mathematical Capacity Example

Polynomial model:

$$
f(x) = \beta_0 + \beta_1 x + \beta_2 x^2 + \cdots + \beta_d x^d
$$

Higher $$d$$ â†’ Higher capacity â†’ Higher overfitting risk.

---

# ðŸ§© Additional Advanced Insights

## VC Dimension (Model Complexity)

Generalization bound:

$$
R(f) \le R_{emp}(f) + O\left(\sqrt{\frac{VC}{N}}\right)
$$

Where:

- model complexity  $$VC$$
- dataset size  $$N$$

Higher complexity requires **more data**.

---

## Double Descent (Modern Insight)

Modern deep learning shows:

- Error decreases â†’ increases â†’ decreases again  
- Occurs when capacity exceeds interpolation threshold  

---

## Overfitting Detection Strategy

Instead of one model:

- Train multiple capacity models  
- Observe validation minima  
- Estimate overfit onset  

---

## Smallâ€‘Data Warning (Important)

When dataset is very small:

- Crossâ€‘validation may be **misleading**
- Overfitting detection unreliable
- High variance estimates

Use:

- Multiple runs  
- Careful validation  
- Simpler models  

---

# ðŸŒŸ Final Core Takeaways

- Training loss must decrease âœ”  
- Validation loss shows generalization âœ”  
- High dimension needs exponential data âœ”  
- Overfitting = learning noise âœ”  
- Capacity must match data âœ”  
- Always validate carefully âœ”  

> The best model is not the one with lowest training loss,  
> but the one with **best generalization and controlled complexity**.
